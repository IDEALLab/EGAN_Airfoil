{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599524974202",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from layers import BezierLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[[0.9839, 0.9441, 0.9343,  ..., 0.5617, 0.4854, 0.0795],\n          [0.2625, 0.2920, 0.2993,  ..., 0.4206, 0.3305, 0.6472]],\n \n         [[0.6119, 0.5772, 0.5715,  ..., 0.4670, 0.4058, 0.3854],\n          [0.4514, 0.4852, 0.4910,  ..., 0.4325, 0.4348, 0.4272]],\n \n         [[0.5376, 0.5389, 0.5392,  ..., 0.2629, 0.3657, 0.5521],\n          [0.4854, 0.4920, 0.4945,  ..., 0.6497, 0.7119, 0.8297]],\n \n         ...,\n \n         [[0.2330, 0.2731, 0.2812,  ..., 0.3196, 0.2388, 0.1885],\n          [0.8605, 0.8325, 0.8268,  ..., 0.4753, 0.5192, 0.5601]],\n \n         [[0.5155, 0.5297, 0.5331,  ..., 0.6445, 0.6823, 0.6880],\n          [0.7260, 0.7326, 0.7342,  ..., 0.2350, 0.2813, 0.4345]],\n \n         [[0.8502, 0.8454, 0.8439,  ..., 0.3689, 0.3202, 0.2813],\n          [0.9526, 0.9361, 0.9312,  ..., 0.7021, 0.7771, 0.8344]]],\n        grad_fn=<DivBackward0>),\n tensor([[0.0000, 0.0529, 0.0128,  ..., 0.0119, 0.0182, 0.0089],\n         [0.0000, 0.0618, 0.0121,  ..., 0.0081, 0.0146, 0.0103],\n         [0.0000, 0.0536, 0.0196,  ..., 0.0175, 0.0184, 0.0127],\n         ...,\n         [0.0000, 0.0728, 0.0146,  ..., 0.0097, 0.0123, 0.0066],\n         [0.0000, 0.0654, 0.0151,  ..., 0.0134, 0.0134, 0.0121],\n         [0.0000, 0.0552, 0.0159,  ..., 0.0137, 0.0125, 0.0090]],\n        grad_fn=<ConstantPadNdBackward>),\n tensor([[[0.0000, 0.0529, 0.0657,  ..., 0.9729, 0.9911, 1.0000]],\n \n         [[0.0000, 0.0618, 0.0739,  ..., 0.9751, 0.9897, 1.0000]],\n \n         [[0.0000, 0.0536, 0.0731,  ..., 0.9689, 0.9873, 1.0000]],\n \n         ...,\n \n         [[0.0000, 0.0728, 0.0873,  ..., 0.9811, 0.9934, 1.0000]],\n \n         [[0.0000, 0.0654, 0.0805,  ..., 0.9745, 0.9879, 1.0000]],\n \n         [[0.0000, 0.0552, 0.0711,  ..., 0.9785, 0.9910, 1.0000]]],\n        grad_fn=<UnsqueezeBackward0>))"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "bl = BezierLayer(10, 20, 40)\n",
    "cp = torch.rand(50, 2, 20) * 1\n",
    "w = torch.rand(50, 1, 20) * 1\n",
    "ipt = torch.rand(50, 10) * 1\n",
    "bl(ipt, cp, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([inf])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "torch.lgamma(torch.Tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}